{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our machine learning project is structured into the following key components:\n",
    "\n",
    "1. `Data Ingestion`: Importing and loading raw data from various sources.\n",
    "2. `Data Preprocessing`: Cleaning and preparing the data by handling missing values, outliers, and ensuring proper formatting.\n",
    "3. `Feature Engineering`: Creating new features or transforming existing ones to improve model performance.\n",
    "4. `Feature Selection`: Identifying and selecting the most important features to improve model efficiency and accuracy.\n",
    "5. `Model Training`: Training machine learning models using the prepared data.\n",
    "6. `Model Building`: Developing and finalizing the model architecture.\n",
    "\n",
    "- At the end, we create a `training_pipeline.py` script that orchestrates the entire workflow, ensuring that all components are executed sequentially, from data ingestion to model building, for a smooth end-to-end process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**`Why use Data Versioning?`**\n",
    "\n",
    "- All the components of our machine learning pipeline are dynamic, meaning that their outputs or artifacts are constantly evolving since we perform multiple experiments. For example:\n",
    "\n",
    "- In Data Ingestion, the data is updated with each run.\n",
    "- In Data Preprocessing, different techniques may be applied, which alter the preprocessed data.\n",
    "- Since these artifacts change every time new data is processed or a different technique is applied, managing versions of these artifacts becomes crucial. This allows us to track changes and ensure reproducibility throughout the project.\n",
    "- To address this challenge, we use Data Versioning. Data versioning helps us maintain a record of all modifications to the data and artifacts, enabling us to:\n",
    "    1. Track the evolution of the data and its transformations.\n",
    "    2. Ensure that the right version of the data is used at each step of the pipeline.\n",
    "    3. Reproduce results consistently, even with updates or changes over time.\n",
    "\n",
    "- By incorporating data versioning, we can effectively manage the dynamic nature of the components and their outputs.\n",
    "\n",
    "- Just as we track and manage code versions using Git, we can use DVC (Data Version Control) to maintain versions of our data. DVC is a version control system specifically designed for handling large datasets and machine learning models.\n",
    "\n",
    "**`Why not Git?`**\n",
    "- Git is great for versioning code, but it has limitations when it comes to large datasets.\n",
    "- Git cant store huge datasets\n",
    "- Resolving conflicts with large data files, such as thousands of rows, can be extremely challenging and time-consuming in Git.\n",
    "- Git repositories may become bloated and slow when large datasets are added, which can make it difficult to collaborate effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`How to Control Versions of Data?`**\n",
    "\n",
    "To effectively manage versions of both code and data, `Git and DVC work together` in the following way:\n",
    "\n",
    "- `Git` manages the versioning of code, including scripts and configurations.\n",
    "- `DVC` manages the versioning of the data, including datasets and models, ensuring that data changes are tracked alongside code changes.\n",
    "\n",
    "`How Does It Work?`\n",
    "\n",
    "1. `Tracking Data`: When you use DVC to track a dataset, DVC generates a unique identifier (ID) for that version of the data.\n",
    "2. `Integration with Git`: This unique data ID is then tracked by Git as part of the projectâ€™s codebase. Git does not store the large data itself, but rather the reference to it.\n",
    "3. `Data and Code Sync`: As you make changes to both the code and the data, DVC tracks and links the data versions to the corresponding changes in the code, ensuring they stay in sync.\n",
    "4. `Rolling Back`: If you need to roll back to a previous version of the code, Git will automatically bring in the correct version of the data associated with that specific code change, using the unique data ID.\n",
    "\n",
    "This integration ensures that you can track both code and data changes together, making it easy to manage versions and reproduce previous environments or results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
